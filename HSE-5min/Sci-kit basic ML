import pandas as pd
import datetime
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from sklearn.metrics import make_scorer
from sklearn.metrics import accuracy_score
from sklearn.model_selection import KFold
from sklearn import preprocessing
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from catboost import CatBoostClassifier

# stacking
from mlxtend.classifier import StackingCVClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier

# doubles train data, based on idea of interchangeble heroes in dire and radiant teams

def data_doubling(df):
    df2 = df.copy(deep=True)
    df2['radiant_win']=df2['radiant_win'].map({1: 0, 0: 1})
    df2_col =df2.columns.tolist()
    j = 0
    # assigning hero columns
    for col in df2.columns:
        for i in range(5):
            if col.count('r%d_' %(i+1))>0: 
                col1 = col.replace('r%d' %(i+1),'d%d' %(i+1))
                df2_col[j]=col1
            elif col.count('d%d_' %(i+1))>0:
                col1 = col.replace('d%d' %(i+1),'r%d' %(i+1))
                df2_col[j]=col1
        j+=1
    
    # assigning team -1/1 columns 
    for field in ['first_blood_team','tower_kill_team','aegis_team','tower_deny_team']:
        df2[field] = df2[field].map({1:-1,-1:1})
   
    # assigning items column
    
    cols =[]
    for col in df.columns:
        if col.count('dire')>0:
            cols.append(col.replace('dire',''))
    for field in cols:
        df2['tmp']=df2['radiant%s' % field]
        df2['radiant%s' % field] = df2['dire%s' % field]
        df2['dire%s' % field] = df2['tmp']
    del df2['tmp']
    
   
    # new index
    df2.columns = df2_col           
    temp_index = list(df2.index)
    temp_index = [x+200000 for x in temp_index]
    df2.index = temp_index
    df = pd.concat([df,df2])
    return df

# add team fields

def add_team_2 (df,fields):
    
    for c in fields:
        r_columns = [f'r{i}{c}' for i in range(1, 6)]
        d_columns = [f'd{i}{c}' for i in range(1, 6)]
        
        df['r_std' + c] = df[r_columns].std(1)
        df['d_std' + c] = df[d_columns].std(1)
        df['std' + c + '_ratio'] = df['r_std' + c] / (df['d_std' + c]+1)
        
        df['r_mean' + c] = df[r_columns].mean(1)
        df['d_mean' + c] = df[d_columns].mean(1)
        df['mean' + c + '_ratio'] = df['r_mean' + c] / (df['d_mean' + c]+1)
        
       
# one-hot encoding of hero id +1 for radiant, -1 for dire 

def heroes_encoding(df):
    N = 121
    X_pick = np.zeros((df.shape[0], N))
    ii=0
    for i in df.index:
        for p in range(5):
            X_pick[ii, int(df.loc[i, 'r%d_hero' % (p+1)])] = 1
            X_pick[ii, int(df.loc[i, 'd%d_hero' % (p+1)])] = -1
        ii+=1
    for i in range(N):
        df['hero_%d' % i]=X_pick[:,i]
    for i in range(5):
        del df['r%d_hero' % (i+1)]
        del df['d%d_hero' % (i+1)]

def item_deletion(df):
    for col in df.columns:
        if col.count('_count')>0:
            del df[col]
    return df

def time_revers(df):
    for col in df.columns:
        if col.count('_time')>0:
            df[col]=df[col].apply(lambda x: 0 if x == None else 300-x)
    return df

def remap_teams(df):
    for field in ['first_blood_team','tower_kill_team','aegis_team','tower_deny_team']:
        df[field] = df[field].map({0:-1})
    return df

# timer on
start_time = datetime.datetime.now()

# data loading, you obiosly need to change the path to your data
df = pd.read_csv(r'DATA_csv\VHS_output-2021-02-25.csv', index_col='match_id')
df_test = pd.read_csv(r'DATA_csv\VHS_output_test-2021-02-25.csv', index_col='match_id')


# deliting columns with negative influence
fields = ['first_blood_player1','first_blood_player2','start_time']
for col in fields: del df[col]; del df_test[col]

# DATA PREPARATION

# fileds for team combining
fields = ['_kills', '_deaths', '_gold', '_lh', '_xp', '_level','_items','_ability_upgrades','_buybacks']

# data processing, normalization and split

df = remap_teams(df)
df = data_doubling(df)
heroes_encoding(df)
add_team_2(df,fields)
df = time_revers(df)
df = item_deletion(df)
df.fillna(value=0, inplace=True)
y = df['radiant_win']

df1 = df.copy()
del df1['radiant_win']
 
# normalized data
Scaler = preprocessing.StandardScaler()
X = Scaler.fit(df1).transform(df1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=241)

# non-normalized data
X_cat = df1.values
X_cat_train, X_cat_test, y_cat_train, y_cat_test = train_test_split(X_cat, y, test_size=0.1, random_state=241)


# TEST DATA
df = remap_teams(df)
heroes_encoding(df_test)
add_team_2(df_test,fields)
df_test = time_revers(df_test)
df_test = item_deletion(df_test)
df_test.fillna(value=0, inplace=True)

# normilized test data
XX = Scaler.transform(df_test)

# non-normilized test data
XX_cat = df_test.values

print('Time elapsed, data prep:', datetime.datetime.now() - start_time)

# cross-validation methods
scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}
kf = KFold(n_splits=5, random_state=241, shuffle=True)

# LightGBM
start_time_l = datetime.datetime.now()
lgbm = LGBMClassifier()
lgbm.fit(X_train,y_train)
yhat = lgbm.predict_proba(X_test)[:,1]
yhat1 = lgbm.predict(X_test)
print('\nLGBM')
print('LGBM, AUC',roc_auc_score(y_test, yhat))
print('LGBM,Accuracy',accuracy_score(y_test, yhat1))
print ('Time elapsed, LGBM:', datetime.datetime.now() - start_time_l)


#CatBoost, best los ='MultiClassOneVsAll',iter = 500, lr=1, depth =2
start_time_l = datetime.datetime.now()
cat = CatBoostClassifier(iterations=500,
                         depth=2,
                         learning_rate=1,
                         loss_function='MultiClassOneVsAll',
                         random_state=241,
                         logging_level='Silent')
cat.fit(X_cat_train,y_cat_train)
print('\nCatBoost')
yhat = cat.predict_proba(X_cat_test)[:,1]
yhat1 = cat.predict(X_cat_test)
print('Catboost, AUC',roc_auc_score(y_cat_test, yhat))
print('Catboost, Accuracy',accuracy_score(y_cat_test, yhat1))
print ('Time elapsed, CatBoost:', datetime.datetime.now() - start_time_l)

"""
# Simple Logistic Regression
start_time_l = datetime.datetime.now()
LR = LogisticRegression(C=1, solver='sag', max_iter = 10000, random_state=241, n_jobs = -1).fit(X_train,y_train)
yhat = LR.predict_proba(X_test)[:,1]
yhat1 = LR.predict(X_test)
print('\nLogReg')
print('simple LR, AUC',roc_auc_score(y_test, yhat))
print('simple LR, Accuracy',accuracy_score(y_test, yhat1))
print ('Time elapsed, simple LR:', datetime.datetime.now() - start_time_l)
"""


# stacking classifier, best fatures class = cat, rnf,lgbm, xgb,(LR) meta = LR, auc 7579(7586), accur 6871
start_time_l = datetime.datetime.now()
cat = CatBoostClassifier(iterations=500, depth=2, learning_rate=1,loss_function='MultiClassOneVsAll',
                         random_state=241,logging_level='Silent')
LR = LogisticRegression(C=1, solver='sag', max_iter = 10000, random_state=241, n_jobs = -1)
rnf = RandomForestClassifier(n_estimators = 30, max_depth=10,random_state=241, n_jobs=-1)
lgbm = LGBMClassifier()
xgb = XGBClassifier()

stack = StackingCVClassifier(classifiers=(lgbm, cat, LR),
                            verbose = 1,
                            meta_classifier=LR,
                            cv=2,
                            use_probas=True,
                            use_features_in_secondary=True,
                            store_train_meta_features=True,
                            shuffle=False,
                            random_state=42,
                            n_jobs=-1
                            )
stack.fit(X_train, y_train)
print('ROC_AUC, Stack',roc_auc_score(y_test, stack.predict_proba(X_test)[:,1]))
print('Accuracy, Stack',accuracy_score(y_test, stack.predict(X_test)))
print ('Time elapsed, Stacking:', datetime.datetime.now() - start_time_l)

"""
# saving predictions to file
result_stack = stack.predict_proba(XX)[:,1]
np.savetxt("Predict_proba.csv", result_stack, delimiter=",")
"""
print ('Time elapsed, Total:', datetime.datetime.now() - start_time)
